from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from agent_library import library
from tools import PubMedTool
import os




class DoctorAgent:
    """
    The DoctorAgent class models a medical diagnostic agent specialized in predicting 
    Alzheimer's disease severity based on input data (Subjective, Assessment, and Plan). 
    It uses a language model (GPT-4 via ChatOpenAI) to analyze and categorize Clinical Dementia Rating (CDR) levels.

    Attributes:
        llm (ChatOpenAI): An instance of the language model (GPT-4) for predictions.
        profile (str): A description or specialization profile of the Doctor Agent.
        prompt_template (PromptTemplate): The template used for generating prompts for the LLM.
        chain (LLMChain): The LLM chain used to generate responses.
        last_response (str): Stores the last response generated by the Doctor Agent.

    Methods:
        predict(subjective, assessment, plan):
            Generates a prediction for Alzheimer's diagnosis and the corresponding CDR level.
        
        revise(feedback, subjective, assessment, plan):
            Revises the previous prediction based on external feedback and updates the response.
    """
    def __init__(self, profile):
        self.llm = ChatOpenAI(model_name='gpt-4')
        self.profile = profile  # Store the profile
        
        self.prompt_template = PromptTemplate(
            input_variables=['subjective', 'assessment', 'plan'], 
            template = f"""
            {profile}
            
            Subjective: {{subjective}}
            Assessment: {{assessment}}
            Plan: {{plan}}
            
            Predict if the patient is diagnosed with Alzheimer's disease. 
            This is a categorization problem, predict the label data in 4 number of CDR level.
            If the patient is diagnosed, determine the Clinical Dementia Rating (CDR) level. 
            The CDR level can only be one of the following values: 0.5, 1.0, 2.0, 3.0.
    
            Your response must include a CDR level in the exact format: "CDR level is X", where X is one of the allowed values. 
            If no diagnosis can be made, explicitly state that no conclusion is possible, but you must give a CDR level,"CDR level is X" closest to the given information.

            Reply with your prediction and the CDR level. Conclude your response with the word 'TERMINATE'.
            """
        )
        self.chain = LLMChain(llm = self.llm, prompt = self.prompt_template)
        self.last_response = ""
        
    def predict(self, subjective, assessment, plan):
        """
        Predicts whether the patient has Alzheimer's disease and determines the corresponding CDR level.

        Args:
            subjective (str): Subjective details of the patient's condition.
            assessment (str): Medical assessment notes.
            plan (str): Proposed medical plan for the patient.

        Returns:
            str: The generated response containing the CDR level.
        """
        response = self.chain.run({
            'subjective': subjective, 
            'assessment': assessment, 
            'plan': plan
        })
        self.last_response = response.strip()
        return self.last_response
    
    def revise(self, feedback, subjective, assessment, plan):
        """
        Revises the last response based on external feedback and generates an updated prediction.

        Args:
            feedback (str): Feedback provided by an external evaluator.
            subjective (str): Subjective details of the patient's condition.
            assessment (str): Medical assessment notes.
            plan (str): Proposed medical plan for the patient.

        Returns:
            str: The revised response containing the updated CDR level.
        """
        revised_prompt_template = PromptTemplate(
            input_variables=['profile', 'last_response', 'feedback', 'subjective', 'assessment', 'plan'],
            template="""
            {profile}
            
            You previously provided the following response:
            {last_response}
            
            The Critical Evaluator provided the following feedback:
            {feedback}
            
            Based on this feedback, revise your original response if necessary.
            Provide your updated prediction and CDR level. Please use 'CDR level is X' Format. When done, reply 'TERMINATE'.
            """
        )
        revised_chain = LLMChain(llm= self.llm, prompt=revised_prompt_template)
        revised_response = revised_chain.run({
            'profile': self.profile,
            'last_response': self.last_response,
            'feedback': feedback,
            'subjective': subjective,
            'assessment': assessment,
            'plan': plan
        })
        self.last_response = revised_response.strip()
        return self.last_response
    



class CriticalEvaluatorAgent:
    """
    The CriticalEvaluatorAgent class represents an external evaluator that critiques the responses 
    generated by the DoctorAgent. It uses PubMed as a source for authoritative references.

    Attributes:
        profile (str): A description of the evaluator's expertise or focus area.
        pubmed_tool (object): A tool for fetching articles and details from PubMed.

    Methods:
        evaluate(doctor_response, subjective, assessment, plan):
        Critically evaluates the DoctorAgent's response using PubMed articles and provides feedback.
    """
    def __init__(self, profile, pubmed_tool):
        self.profile = profile
        self.pubmed_tool = pubmed_tool
        
    def evaluate(self, doctor_response, subjective, assessment, plan):
        """
        Critically evaluates the DoctorAgent's response using PubMed articles and provides feedback.

        Args:
            doctor_response (str): The response provided by the DoctorAgent.
            subjective (str): Subjective details of the patient's condition.
            assessment (str): Medical assessment notes.
            plan (str): Proposed medical plan for the patient.

        Returns:
            str: Feedback based on PubMed articles, including whether the response is supported or challenged.
        """
        query = f"""
        {self.profile}
        
        The Doctor Agent has responded with the following:
        {doctor_response}
        
        Critically evaluate the response. Use authoritative external sources to support or challenge the conclusion.
        Consider the following:
        - Subjective: {subjective}
        - Assessment: {assessment}
        - Plan: {plan}
        """

        articles = self.pubmed_tool.get_articles(query)
        
        if not articles:
            return f'No relevant articles found in PubMed for the query. TERMINATE.'
        
        articles_summary = []
        for article_id in articles[:3]: 
            article_details = self.pubmed_tool.fetch_article_details(article_id)
            articles_summary.append(article_details)
        
        feedback = (
            "Based on the retrieved articles from PubMed:\n"
            + "\n".join(articles_summary) + "\n\n"
            + "The Doctor Agent's response has been critically evaluated using external sources. TERMINATE."
        )
        
        return feedback.strip()